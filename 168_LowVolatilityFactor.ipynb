{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6d349e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000;\"><img src=\"pqn.png\"></img></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f0e80",
   "metadata": {},
   "source": [
    "We use warnings to filter messages, numpy and pandas for fast calculations, and Zipline libraries for running backtests, managing orders, simulating trading costs, creating data pipelines, and working with stock price and factor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipline import run_algorithm\n",
    "from zipline.api import (\n",
    "    attach_pipeline,\n",
    "    cancel_order,\n",
    "    date_rules,\n",
    "    get_datetime,\n",
    "    get_open_orders,\n",
    "    order_target_percent,\n",
    "    pipeline_output,\n",
    "    schedule_function,\n",
    "    set_commission,\n",
    "    set_slippage,\n",
    "    time_rules,\n",
    ")\n",
    "from zipline.finance import commission, slippage\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.data import USEquityPricing\n",
    "from zipline.pipeline.factors import AverageDollarVolume, CustomFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ac72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367c5c2",
   "metadata": {},
   "source": [
    "This code sets up a few key parameters we’ll use for our historical lookback window and to determine the size of the universe we analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK_WEEKS = 151\n",
    "LOOKBACK_DAYS = LOOKBACK_WEEKS * 5\n",
    "UNIVERSE_SIZE = 3000\n",
    "QUANTILE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22db19",
   "metadata": {},
   "source": [
    "These variables control how far back we look (about three years), how many stocks we consider (3000), and how we divide them into groups for ranking (quartiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555d433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b159d90f",
   "metadata": {},
   "source": [
    "## Build custom stock factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddaf4f7",
   "metadata": {},
   "source": [
    "Here, we define a custom factor to measure weekly volatility and build a pipeline that selects stocks with the lowest volatility from higher-volume names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd032bff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class WeeklyVolatility(CustomFactor):\n",
    "    \"\"\"\n",
    "    Computes standard deviation of weekly returns over a 3-year window.\n",
    "    Weekly return is defined over 5 consecutive trading days:\n",
    "        r_week = (close[t] / close[t-4]) - 1\n",
    "    We take non-overlapping 5-day chunks across the window for stability.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = [USEquityPricing.close]\n",
    "    window_length = LOOKBACK_DAYS\n",
    "\n",
    "    def compute(self, today, assets, out, closes):\n",
    "        n_weeks = closes.shape[0] // 5\n",
    "        if n_weeks < 2:  # not enough weeks to compute a standard deviation\n",
    "            out[:] = np.nan\n",
    "            return\n",
    "\n",
    "        trimmed = closes[-n_weeks * 5 :, :]  # (n_weeks*5, n_assets)\n",
    "        weekly_open = trimmed[::5, :]  # first close in each 5-day block\n",
    "        weekly_close = trimmed[4::5, :]  # last close in each 5-day block\n",
    "        weekly_rets = (weekly_close / weekly_open) - 1  # shape (n_weeks, n_assets)\n",
    "\n",
    "        out[:] = np.nanstd(weekly_rets, axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9389a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    adv20 = AverageDollarVolume(window_length=20)\n",
    "    base_universe = adv20.top(UNIVERSE_SIZE)\n",
    "\n",
    "    vol = WeeklyVolatility(mask=base_universe)\n",
    "    # Select lowest-volatility quartile by taking the bottom N within the ADV-filtered universe.\n",
    "    target_count = max(1, UNIVERSE_SIZE // QUANTILE)\n",
    "    lows = vol.bottom(target_count, mask=base_universe)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        columns={\n",
    "            \"adv20\": adv20,\n",
    "            \"vol\": vol,\n",
    "            \"low_vol_long\": lows,\n",
    "        },\n",
    "        screen=base_universe,\n",
    "    )\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59583159",
   "metadata": {},
   "source": [
    "In this block, we create a special stock ranking that calculates how much a stock’s price jumps around from week to week over the last three years. We only consider stocks with good trading volume. We then sort these stocks and filter down to those with the most stable (least volatile) prices, forming our candidate list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93389b7",
   "metadata": {},
   "source": [
    "By defining a custom calculation for weekly volatility, we’re able to focus on stocks with lower risk. The pipeline groups our target stocks by filtering out those that don’t trade enough and then scoring what’s left, so each month we can focus on the most stable performers. This process uses Zipline’s factor modeling tools, making it easy to plug into the rest of our analysis. We return a data pipeline that tags each qualifying stock with its volume, its volatility, and a flag for inclusion in our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eabcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4588cd8",
   "metadata": {},
   "source": [
    "## Configure and execute the trading strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a13d9f",
   "metadata": {},
   "source": [
    "Next, we set up our strategy to use the custom data pipeline, schedule when we rebalance, and decide which stocks to hold at each rebalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab731338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(context):\n",
    "    # Attach pipeline\n",
    "    attach_pipeline(make_pipeline(), \"lowvol_pipe\")\n",
    "\n",
    "    # Monthly rebalance at market open (first trading day)\n",
    "    schedule_function(\n",
    "        rebalance, date_rules.month_start(), time_rules.market_open(minutes=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2252d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_trading_start(context, data):\n",
    "    # Pull latest factor data\n",
    "    context.pipe = pipeline_output(\"lowvol_pipe\")\n",
    "\n",
    "    # Determine long basket (lowest-vol quartile)\n",
    "    longs_frame = context.pipe[context.pipe[\"low_vol_long\"]]\n",
    "    context.long_assets = list(longs_frame.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance(context, data):\n",
    "\n",
    "    # Filter tradable and priced today\n",
    "    tradable_longs = [a for a in context.long_assets if data.can_trade(a)]\n",
    "\n",
    "    if len(tradable_longs) == 0:\n",
    "        # Nothing tradable; flatten all positions\n",
    "        for asset in list(context.portfolio.positions.keys()):\n",
    "            if data.can_trade(asset):\n",
    "                order_target_percent(asset, 0.0)\n",
    "        return\n",
    "\n",
    "    # Target equal weights across long basket (long-only)\n",
    "    w = 1.0 / float(len(tradable_longs))\n",
    "\n",
    "    # Cancel any open orders to avoid drift\n",
    "    oo = get_open_orders()\n",
    "    for asset, orders in oo.items():\n",
    "        for o in orders:\n",
    "            cancel_order(o)\n",
    "\n",
    "    # Close positions that are no longer in the target basket\n",
    "    current_pos = list(context.portfolio.positions.keys())\n",
    "    for asset in current_pos:\n",
    "        if asset not in tradable_longs and data.can_trade(asset):\n",
    "            order_target_percent(asset, 0.0)\n",
    "\n",
    "    # Set target weights for longs\n",
    "    for asset in tradable_longs:\n",
    "        order_target_percent(asset, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0afb3",
   "metadata": {},
   "source": [
    "This code ties everything together for live backtesting. Each month, we update our list of low-volatility stocks and assign equal weights to each, selling anything that’s no longer in our target group. When nothing in our group can be traded that day, we exit all positions. We also make sure to clean up any outstanding orders before placing new ones to avoid unnecessary trading. Scheduling and pipeline hooks make the whole process hands-off once started, keeping our portfolio focused and up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c335c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea19a0b2",
   "metadata": {},
   "source": [
    "## Run backtest and plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780e1cb",
   "metadata": {},
   "source": [
    "Now, we set the backtest period, run the simulation using Quandl US price data, and graph how the strategy’s value grows over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.Timestamp(\"2015\")\n",
    "end = pd.Timestamp(\"2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = run_algorithm(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    initialize=initialize,\n",
    "    before_trading_start=before_trading_start,\n",
    "    capital_base=100_000,\n",
    "    bundle=\"quandl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da66ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.portfolio_value.plot(title=\"Low Volatility Factor Equity Curve\", ylabel=\"Strategy Equity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79dbbd2",
   "metadata": {},
   "source": [
    "Here, we run a full portfolio simulation over three years, tracking how a $100,000 account grows if we always hold the least volatile, high-volume US stocks. Zipline uses actual historical pricing from Quandl, making the results realistic for live trading. The plot gives us a clear picture of how steady or bumpy our approach might feel in the real world. By checking this chart, we quickly see if our low-volatility approach actually produced smoother and stronger returns than just holding the market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02159e9e",
   "metadata": {},
   "source": [
    "<a href=\"https://pyquantnews.com/\">PyQuant News</a> is where finance practitioners level up with Python for quant finance, algorithmic trading, and market data analysis. Looking to get started? Check out the fastest growing, top-selling course to <a href=\"https://gettingstartedwithpythonforquantfinance.com/\">get started with Python for quant finance</a>. For educational purposes. Not investment advice. Use at your own risk."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
